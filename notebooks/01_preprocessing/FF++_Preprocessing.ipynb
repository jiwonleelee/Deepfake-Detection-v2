{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiwonleelee/Deepfake-Detection-v2/blob/main/notebooks/01_preprocessing/FF%2B%2B_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install insightface onnxruntime-gpu"
      ],
      "metadata": {
        "id": "jQsp_PSHRXlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import os\n",
        "import json\n",
        "import urllib.request\n",
        "import tempfile\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from insightface.app import FaceAnalysis\n",
        "\n",
        "import shutil\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "n5gEePfQTquz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "smlzFBDvSadc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# 2. ff_utils.pyê°€ ì €ì¥ëœ 'í´ë”' ê²½ë¡œë¥¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€\n",
        "# ì£¼ì˜: íŒŒì¼ëª…ì´ ì•„ë‹ˆë¼ íŒŒì¼ì´ ë“¤ì–´ìˆëŠ” 'í´ë”'ê¹Œì§€ë§Œ ì ì–´ì£¼ì„¸ìš”.\n",
        "MODULE_PATH = \"/content/drive/MyDrive/Deepfake-Detection-v2/src\"\n",
        "if MODULE_PATH not in sys.path:\n",
        "    sys.path.append(MODULE_PATH)\n",
        "\n",
        "# 3. ì´ì œ ì„í¬íŠ¸ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤\n",
        "import pp_utils\n",
        "import importlib\n",
        "importlib.reload(pp_utils) # ì½”ë“œë¥¼ ìˆ˜ì •í•˜ê³  ë‹¤ì‹œ ì €ì¥í–ˆì„ ë•Œ ë°˜ì˜í•˜ê¸° ìœ„í•¨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR14nq0TKnJW",
        "outputId": "8bcaff1a-1686-48cb-e30d-c5b106937582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'pp_utils' from '/content/drive/MyDrive/Deepfake-Detection-v2/src/pp_utils.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ì„¤ì • ìˆ˜ì • ---\n",
        "LOCAL_BASE_PATH = \"/content/FF_frames_local\"  # ì½”ë© ë¡œì»¬ ê²½ë¡œì—ì„œ ì‘ì—…\n",
        "GDRIVE_SAVE_BASE = \"/content/drive/MyDrive/Deepfake-Detection-v2/Datasets/FF++\" # ê²°ê³¼ë¬¼ì´ ì €ì¥ë  êµ¬ë“œ í´ë”\n",
        "GDRIVE_ZIP_PATH = os.path.join(GDRIVE_SAVE_BASE, \"FF_frames.zip\")\n",
        "JSON_DB_PATH = os.path.join(GDRIVE_SAVE_BASE, \"ff_face_metadata.json\")\n",
        "VERIFY_SAVE_PATH = os.path.join(GDRIVE_SAVE_BASE, \"FF_Verification\")\n",
        "\n",
        "# êµ¬ë“œì— ì €ì¥\n",
        "FINAL_SAVE_PATH = \"/content/drive/MyDrive/Deepfake-Detection-v2/Datasets/FF++/Images\"\n",
        "\n",
        "NUM_FRAMES = 15\n",
        "SERVER_URL = \"http://kaldir.vc.in.tum.de/faceforensics/v3/\"\n",
        "FILELIST_URL = SERVER_URL + \"misc/filelist.json\"\n",
        "MANIPULATIONS = ['Deepfakes', 'Face2Face', 'FaceSwap', 'NeuralTextures']\n",
        "COMPRESSION = 'c23'"
      ],
      "metadata": {
        "id": "IsqQRx8kbRTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RetinaFace ì´ˆê¸°í™” (ëœë“œë§ˆí¬ ì¶”ì¶œì„ ìœ„í•´ landmark2d ì¶”ê°€)\n",
        "detector = FaceAnalysis(allowed_modules=['detection', 'landmark_2d'], providers=['CUDAExecutionProvider'])\n",
        "detector.prepare(ctx_id=0, det_size=(640, 640))\n",
        "\n",
        "def resize_with_letterbox(image, target_size=(512, 512)):\n",
        "    if image.size == 0: return np.zeros((target_size[1], target_size[0], 3), dtype=np.uint8)\n",
        "    h, w = image.shape[:2]\n",
        "    scale = min(target_size[0]/w, target_size[1]/h)\n",
        "    nw, nh = int(w * scale), int(h * scale)\n",
        "\n",
        "    img_resized = cv2.resize(image, (nw, nh))\n",
        "    canvas = np.zeros((target_size[1], target_size[0], 3), dtype=np.uint8)\n",
        "    dx, dy = (target_size[0]-nw)//2, (target_size[1]-nh)//2\n",
        "    canvas[dy:dy+nh, dx:dx+nw] = img_resized\n",
        "    return canvas"
      ],
      "metadata": {
        "id": "6XIt8uaPP611"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_extract_combined(video_names, sub_path, category_name, label, detector, is_real=True):\n",
        "    # êµ¬ê¸€ ë“œë¼ì´ë¸Œ ìµœì¢… ì €ì¥ ê²½ë¡œ ì„¤ì •\n",
        "    save_dir = os.path.join(FINAL_SAVE_PATH, category_name)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # JSON DB ë¡œë“œ (ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì™€ì„œ ì´ì–´ì„œ ì‘ì—…)\n",
        "    metadata = {}\n",
        "    if os.path.exists(JSON_DB_PATH):\n",
        "        with open(JSON_DB_PATH, 'r') as f:\n",
        "            metadata = json.load(f)\n",
        "\n",
        "    for v_name in tqdm(video_names, desc=f\"Processing {category_name}\"):\n",
        "        video_id = v_name.split('.')[0]\n",
        "        video_folder = os.path.join(save_dir, video_id)\n",
        "\n",
        "        # ğŸ”¥ [ì´ì–´í•˜ê¸° ë¡œì§] ì´ë¯¸ í´ë”ê°€ ìˆê³  í”„ë ˆì„ì´ ë‹¤ ì°¨ìˆìœ¼ë©´ ìŠ¤í‚µ\n",
        "        if os.path.exists(video_folder) and len(os.listdir(video_folder)) >= NUM_FRAMES:\n",
        "            continue\n",
        "\n",
        "        os.makedirs(video_folder, exist_ok=True)\n",
        "        video_url = SERVER_URL + sub_path + v_name\n",
        "        target_id = video_id.split('_')[0] if not is_real else video_id\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(suffix='.mp4') as temp_v:\n",
        "            try:\n",
        "                urllib.request.urlretrieve(video_url, temp_v.name)\n",
        "                cap = cv2.VideoCapture(temp_v.name)\n",
        "                total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "                if total <= 0: continue\n",
        "                interval = max(1, total // NUM_FRAMES)\n",
        "\n",
        "                last_face_info = None\n",
        "                video_faces_found = False\n",
        "                frames_cache = []\n",
        "                face_crops_temp = []\n",
        "                current_video_metadata = [None] * NUM_FRAMES\n",
        "\n",
        "                for i in range(NUM_FRAMES):\n",
        "                    cap.set(cv2.CAP_PROP_POS_FRAMES, i * interval)\n",
        "                    ret, frame = cap.read()\n",
        "                    if not ret or frame is None:\n",
        "                        face_crops_temp.append(None)\n",
        "                        continue\n",
        "\n",
        "                    frames_cache.append(frame)\n",
        "                    face_to_save = None\n",
        "                    used_info = None\n",
        "\n",
        "                    if is_real:\n",
        "                        # [REAL] GPU ê°€ì† ì–¼êµ´ ê²€ì¶œ\n",
        "                        faces = detector.get(frame)\n",
        "                        if faces:\n",
        "                            used_info = max(faces, key=lambda x: (x.bbox[2]-x.bbox[0]) * (x.bbox[3]-x.bbox[1]))\n",
        "                            face_to_save = pp_utils.get_aligned_face(frame, used_info)\n",
        "\n",
        "                            if face_to_save is not None:\n",
        "                                # ì†Œê¸‰ ì ìš©\n",
        "                                if not video_faces_found and i > 0:\n",
        "                                    for prev_idx in range(len(face_crops_temp)):\n",
        "                                        if face_crops_temp[prev_idx] is None:\n",
        "                                            retro_crop = pp_utils.get_aligned_face(frames_cache[prev_idx], used_info)\n",
        "                                            face_crops_temp[prev_idx] = retro_crop\n",
        "                                            current_video_metadata[prev_idx] = {\n",
        "                                                \"bbox\": used_info.bbox.tolist(),\n",
        "                                                \"kps\": used_info.kps.tolist() if hasattr(used_info, 'kps') else None\n",
        "                                            }\n",
        "                                last_face_info = used_info\n",
        "                                video_faces_found = True\n",
        "\n",
        "                        if face_to_save is None and last_face_info is not None:\n",
        "                            face_to_save = pp_utils.get_aligned_face(frame, last_face_info)\n",
        "                            used_info = last_face_info\n",
        "                    else:\n",
        "                        # [FAKE] JSON ì¢Œí‘œ ì¬í™œìš© (êµ¬ë“œì—ì„œ ë¶ˆëŸ¬ì˜¨ metadata ì‚¬ìš©)\n",
        "                        if target_id in metadata and i < len(metadata[target_id]):\n",
        "                            info = metadata[target_id][i]\n",
        "                            if info:\n",
        "                                class FaceInfo: pass\n",
        "                                used_info = FaceInfo()\n",
        "                                used_info.bbox = np.array(info['bbox'])\n",
        "                                used_info.kps = np.array(info['kps']) if info['kps'] else None\n",
        "                                face_to_save = pp_utils.get_aligned_face(frame, used_info)\n",
        "                                video_faces_found = True\n",
        "\n",
        "                    face_crops_temp.append(face_to_save)\n",
        "                    if is_real and used_info and face_to_save is not None:\n",
        "                        current_video_metadata[i] = {\n",
        "                            \"bbox\": used_info.bbox.tolist(),\n",
        "                            \"kps\": used_info.kps.tolist() if hasattr(used_info, 'kps') else None\n",
        "                        }\n",
        "\n",
        "                # íŒŒì¼ ì €ì¥ (êµ¬ê¸€ ë“œë¼ì´ë¸Œë¡œ ì§ì ‘ ì“°ê¸°)\n",
        "                if video_faces_found:\n",
        "                    for idx, crop in enumerate(face_crops_temp):\n",
        "                        if crop is not None:\n",
        "                            cv2.imwrite(os.path.join(video_folder, f\"f{idx:03d}_{label}.jpg\"), crop)\n",
        "                else:\n",
        "                  # ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨ ì‹œ ì „ì²´ ì´ë¯¸ì§€ ì €ì¥í•˜ì§€ ì•Šê³  í´ë” ì‚­ì œ í›„ ìŠ¤í‚µ\n",
        "                  print(f\"âš ï¸ {video_id}: ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨ë¡œ ì œì™¸í•©ë‹ˆë‹¤.\")\n",
        "                  if os.path.exists(video_folder):\n",
        "                    shutil.rmtree(video_folder)\n",
        "\n",
        "                # ğŸ”¥ [ì¤‘ìš”] ë§¤ ì˜ìƒ ì™„ë£Œ ì‹œë§ˆë‹¤ JSON ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸\n",
        "                if is_real:\n",
        "                    metadata[video_id] = current_video_metadata\n",
        "                    with open(JSON_DB_PATH, 'w') as f:\n",
        "                        json.dump(metadata, f)\n",
        "\n",
        "                cap.release()\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Error {v_name}: {e}\")"
      ],
      "metadata": {
        "id": "I5Gy9v-DQRSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ìƒ˜í”Œ í™•ì¸ ì„¤ì • ---\n",
        "def run_visual_verification(detector):\n",
        "    \"\"\"\n",
        "    ê° ì¡°ì‘ ë°©ì‹ë³„ë¡œ ì²« ë²ˆì§¸ Fake ì˜ìƒì„ ì„ ì •í•˜ê³ ,\n",
        "    ê·¸ì— ëŒ€ì‘í•˜ëŠ” Real ì˜ìƒì„ ìë™ìœ¼ë¡œ ì°¾ì•„ ê²€ì¦ ë¦¬ìŠ¤íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    print(\"ğŸ” ìƒ˜í”Œ ê²€ì¦ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "    if os.path.exists(VERIFY_SAVE_PATH):\n",
        "        shutil.rmtree(VERIFY_SAVE_PATH)\n",
        "    os.makedirs(VERIFY_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "    # 1. ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
        "    real_videos, fake_videos_dict = pp_utils.get_id_matched_dataset()\n",
        "    verify_list = []\n",
        "    temp_metadata = {}\n",
        "\n",
        "    # 2. ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ Fake ìƒ˜í”Œ í•˜ë‚˜ì”© ì„ ì •í•˜ê³ , ëŒ€ì‘í•˜ëŠ” Realë„ ì„¸íŠ¸ë¡œ ì¶”ê°€\n",
        "    # ì´ë ‡ê²Œ í•´ì•¼ Fake ì²˜ë¦¬ ì‹œ í•„ìš”í•œ Realì˜ JSON ì¢Œí‘œê°€ ë°˜ë“œì‹œ ì¡´ì¬í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
        "    for method in MANIPULATIONS:\n",
        "        v_list = fake_videos_dict.get(method, [])\n",
        "        if not v_list:\n",
        "            print(f\"âš ï¸ ê²½ê³ : {method} ì¹´í…Œê³ ë¦¬ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            continue\n",
        "\n",
        "        # ì²« ë²ˆì§¸ ê°€ì§œ ì˜ìƒ ì„ íƒ (ì˜ˆ: '751_752.mp4')\n",
        "        fake_v_name = v_list[0]\n",
        "        target_id = fake_v_name.split('_')[0] # '751' ì¶”ì¶œ\n",
        "\n",
        "        # í•´ë‹¹ ê°€ì§œ ì˜ìƒì˜ ì›ë³¸(Real) íŒŒì¼ëª… ìƒì„± (ì˜ˆ: '751.mp4')\n",
        "        real_v_name = target_id + \".mp4\"\n",
        "\n",
        "        if real_v_name in real_videos:\n",
        "            # Real ë¨¼ì € ì¶”ê°€ (ì¢Œí‘œ ìƒì„±ì„ ìœ„í•´)\n",
        "            verify_list.append((\"Real\", [real_v_name], f\"original_sequences/youtube/{COMPRESSION}/videos/\", 0, True))\n",
        "            # ê·¸ ë‹¤ìŒ Fake ì¶”ê°€ (ì¢Œí‘œ ì¬í™œìš©ì„ ìœ„í•´)\n",
        "            verify_list.append((f\"Fake/{method}\", [fake_v_name], f\"manipulated_sequences/{method}/{COMPRESSION}/videos/\", 1, False))\n",
        "        else:\n",
        "            print(f\"âš ï¸ ê²½ê³ : {method}ì˜ íƒ€ê²Ÿ ID {target_id}ì— í•´ë‹¹í•˜ëŠ” ì›ë³¸ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    # 3. ìœ„ì—ì„œ êµ¬ì„±ëœ ë¦¬ìŠ¤íŠ¸ ìˆœì°¨ ì²˜ë¦¬\n",
        "    for category, v_names, sub_path, label, is_real in verify_list:\n",
        "        v_name = v_names[0]\n",
        "        video_id = v_name.split('.')[0]\n",
        "        target_id = video_id.split('_')[0] if not is_real else video_id\n",
        "\n",
        "        # ì˜ìƒë³„ ê°œë³„ í´ë” ìƒì„±\n",
        "        video_folder = os.path.join(VERIFY_SAVE_PATH, category, video_id)\n",
        "        os.makedirs(video_folder, exist_ok=True)\n",
        "\n",
        "        print(f\"ğŸ“¸ {category} ì²˜ë¦¬ ì¤‘: {video_id}\")\n",
        "        video_url = SERVER_URL + sub_path + v_name\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(suffix='.mp4') as temp_v:\n",
        "            try:\n",
        "                urllib.request.urlretrieve(video_url, temp_v.name)\n",
        "                cap = cv2.VideoCapture(temp_v.name)\n",
        "                for i in range(5): # 5í”„ë ˆì„ì”© ê²€ì¦\n",
        "                    cap.set(cv2.CAP_PROP_POS_FRAMES, i * 10)\n",
        "                    ret, frame = cap.read()\n",
        "                    if not ret: break\n",
        "\n",
        "                    face_to_save = None\n",
        "                    if is_real:\n",
        "                        # [REAL] ì§ì ‘ ê²€ì¶œ ë° ì¢Œí‘œ ì €ì¥\n",
        "                        faces = detector.get(frame)\n",
        "                        if faces:\n",
        "                            # scoreê°€ Noneì¸ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ 0.0 ì²˜ë¦¬\n",
        "                            used_info = sorted(faces, key=lambda x: (getattr(x, 'score', 0.0) or 0.0), reverse=True)[0]\n",
        "                            face_to_save = pp_utils.get_aligned_face(frame, used_info)\n",
        "                            if target_id not in temp_metadata: temp_metadata[target_id] = []\n",
        "                            temp_metadata[target_id].append({\n",
        "                                \"bbox\": used_info.bbox.tolist(),\n",
        "                                \"kps\": used_info.kps.tolist() if hasattr(used_info, 'kps') else None\n",
        "                            })\n",
        "                    else:\n",
        "                        # [FAKE] ì €ì¥ëœ ì¢Œí‘œ ì¬í™œìš©\n",
        "                        if target_id in temp_metadata and i < len(temp_metadata[target_id]):\n",
        "                            class FaceInfo: pass\n",
        "                            info = temp_metadata[target_id][i]\n",
        "                            f_obj = FaceInfo()\n",
        "                            f_obj.bbox = np.array(info['bbox'])\n",
        "                            f_obj.kps = np.array(info['kps']) if info['kps'] else None\n",
        "                            face_to_save = pp_utils.get_aligned_face(frame, f_obj)\n",
        "\n",
        "                    if face_to_save is not None:\n",
        "                        cv2.imwrite(os.path.join(video_folder, f\"f{i:03d}_{label}.jpg\"), face_to_save)\n",
        "                cap.release()\n",
        "            except Exception as e:\n",
        "                print(f\"   -> âŒ {video_id} ì—ëŸ¬: {e}\")\n",
        "\n",
        "    print(f\"\\nâœ… ê²€ì¦ ì™„ë£Œ! êµ¬ê¸€ ë“œë¼ì´ë¸Œ í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”: {VERIFY_SAVE_PATH}\")"
      ],
      "metadata": {
        "id": "3lRljISdkN0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. í™˜ê²½ ì¤€ë¹„ (í´ë” ì‚­ì œ ë¡œì§ ì œê±° - ì´ì–´í•˜ê¸°ë¥¼ ìœ„í•´)\n",
        "if not os.path.exists(FINAL_SAVE_PATH):\n",
        "    os.makedirs(FINAL_SAVE_PATH, exist_ok=True)\n",
        "    print(f\"âœ… ìƒˆ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±: {FINAL_SAVE_PATH}\")\n",
        "else:\n",
        "    print(f\"â„¹ï¸ ê¸°ì¡´ ë””ë ‰í† ë¦¬ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤. (ì´ì–´í•˜ê¸° ëª¨ë“œ)\")\n",
        "\n",
        "# 2. ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„\n",
        "real_videos, fake_videos_dict = pp_utils.get_id_matched_dataset(FILELIST_URL, MANIPULATIONS)\n",
        "\n",
        "# 3. ë³¸ ì‘ì—… ì‹œì‘\n",
        "print(\"\\nğŸ¬ [1/2] Real ì˜ìƒ ì²˜ë¦¬ ë° JSON ì¢Œí‘œ DB êµ¬ì¶• ì‹œì‘...\")\n",
        "real_sub_path = f\"original_sequences/youtube/{COMPRESSION}/videos/\"\n",
        "process_and_extract_combined(real_videos, real_sub_path, \"Real\", 0, detector, is_real=True)\n",
        "\n",
        "print(\"\\nğŸ¬ [2/2] Fake ì˜ìƒ ID ë§¤ì¹­ ì²˜ë¦¬ ì‹œì‘ (ì¢Œí‘œ ì¬í™œìš©)...\")\n",
        "for method, v_list in fake_videos_dict.items():\n",
        "    fake_sub_path = f\"manipulated_sequences/{method}/{COMPRESSION}/videos/\"\n",
        "    process_and_extract_combined(v_list, fake_sub_path, f\"Fake/{method}\", 1, detector, is_real=False)\n",
        "\n",
        "print(\"\\nğŸ‰ ëª¨ë“  ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo0hhhIclGf_",
        "outputId": "a5df186c-2144-44b7-ce1f-9aebd7432940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â„¹ï¸ ê¸°ì¡´ ë””ë ‰í† ë¦¬ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤. (ì´ì–´í•˜ê¸° ëª¨ë“œ)\n",
            "\n",
            "ğŸ¬ [1/2] Real ì˜ìƒ ì²˜ë¦¬ ë° JSON ì¢Œí‘œ DB êµ¬ì¶• ì‹œì‘...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Real: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [1:59:51<00:00,  7.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ¬ [2/2] Fake ì˜ìƒ ID ë§¤ì¹­ ì²˜ë¦¬ ì‹œì‘ (ì¢Œí‘œ ì¬í™œìš©)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Fake/Deepfakes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [24:28<00:00,  5.87s/it]\n",
            "Processing Fake/Face2Face: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [26:24<00:00,  6.34s/it]\n",
            "Processing Fake/FaceSwap: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [29:42<00:00,  7.13s/it]\n",
            "Processing Fake/NeuralTextures: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [28:48<00:00,  6.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ‰ ëª¨ë“  ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ í™•ì¸í•˜ì„¸ìš”.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}